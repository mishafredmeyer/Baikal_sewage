# Script for word frequency enumeration
library(tidyverse)
library(tm)
library(wordcloud2)
library(viridis)
library(maps)
library(janitor)
library(htmlwidgets)
library(webshot)
# Import each text file
whole_data <- read.csv(file = "../data/Virtual Summit_ Incorporating Open Science & Data Science Techniques in Limnology and Oceanography (Responses) - Form Responses 1.csv")
whole_data <- clean_names(whole_data)
open_science_abstracts <- whole_data %>%
filter(name %in% c("Corinna Gries", "Michael Meyer", "Eric Pedersen",
"Robert Ladwig", "Marcus Beck", "Clayton Williams",
"Mark Scheuerell", "Matthew R.V. Ross", "Jeff Hollister")) %>%
select(name, talk_title, talk_abstract)
# First create text_in with only the abstracts
text_in <- open_science_abstracts$talk_abstract
# Remove NAs
text_in <- text_in[which(is.na(text_in)==FALSE)]
# For these procedures, object needs to be of class Corpus
text0 <- Corpus(VectorSource(text_in))
# Various text processing steps.
text <- TermDocumentMatrix(text0,
control =
list(removePunctuation = TRUE,
stopwords = TRUE,
tolower = TRUE,
stemming = FALSE,
removeNumbers = TRUE,
bounds = list(global = c(1, Inf))))
ft <- findFreqTerms(text, lowfreq = 4, highfreq = Inf)
ft_matrix <- as.matrix(text[ft,])
sorted_matrix <- data.frame(sort(apply(ft_matrix, 1, sum), decreasing = TRUE)) %>%
rownames_to_column() %>%
rename("word" = "rowname",
"frequency" = "sort.apply.ft_matrix..1..sum...decreasing...TRUE.") %>%
filter(!(word %in% c("will", "using", "high", "may", "also", "often", "however", "many",
"well", "ler")))
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = plasma(50)[c(1:40)], backgroundColor = "white")
cloud
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = plasma(50)[c(1:35)], backgroundColor = "white")
cloud
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = viridis(50), backgroundColor = "white")
cloud
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = inferno(50), backgroundColor = "white")
cloud
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = magma(50), backgroundColor = "white")
cloud
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = plasma(50), backgroundColor = "white")
cloud
set.seed(1234)
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = plasma(50), backgroundColor = "white")
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = plasma(50), backgroundColor = "black")
cloud
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = plasma(50), backgroundColor = "black")
cloud
library(wordcloud2)
library(viridis)
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = plasma(50), backgroundColor = "black")
cloud
library(tidyverse)
library(tm)
library(wordcloud2)
library(viridis)
library(maps)
library(janitor)
library(htmlwidgets)
library(webshot)
# Import each text file
whole_data <- read.csv(file = "../data/Virtual Summit_ Incorporating Open Science & Data Science Techniques in Limnology and Oceanography (Responses) - Form Responses 1.csv")
whole_data <- clean_names(whole_data)
open_science_abstracts <- whole_data %>%
filter(name %in% c("Corinna Gries", "Michael Meyer", "Eric Pedersen",
"Robert Ladwig", "Marcus Beck", "Clayton Williams",
"Mark Scheuerell", "Matthew R.V. Ross", "Jeff Hollister")) %>%
select(name, talk_title, talk_abstract)
# First create text_in with only the abstracts
text_in <- open_science_abstracts$talk_abstract
# Remove NAs
text_in <- text_in[which(is.na(text_in)==FALSE)]
# For these procedures, object needs to be of class Corpus
text0 <- Corpus(VectorSource(text_in))
# Various text processing steps.
text <- TermDocumentMatrix(text0,
control =
list(removePunctuation = TRUE,
stopwords = TRUE,
tolower = TRUE,
stemming = FALSE,
removeNumbers = TRUE,
bounds = list(global = c(1, Inf))))
ft <- findFreqTerms(text, lowfreq = 4, highfreq = Inf)
ft_matrix <- as.matrix(text[ft,])
sorted_matrix <- data.frame(sort(apply(ft_matrix, 1, sum), decreasing = TRUE)) %>%
rownames_to_column() %>%
rename("word" = "rowname",
"frequency" = "sort.apply.ft_matrix..1..sum...decreasing...TRUE.") %>%
filter(!(word %in% c("will", "using", "high", "may", "also", "often", "however", "many",
"well", "ler", "five")))
### World Cloud
webshot::install_phantomjs()
set.seed(1234)
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = plasma(50), backgroundColor = "black")
cloud
data_science_abstracts <- whole_data %>%
filter(!(name %in% c("Corinna Gries", "Michael Meyer", "Eric Pedersen",
"Robert Ladwig", "Marcus Beck", "Clayton Williams",
"Mark Scheuerell", "Matthew R.V. Ross", "Jeff Hollister"))) %>%
select(name, talk_title, talk_abstract)
# First create text_in with only the abstracts
text_in <- data_science_abstracts$talk_abstract
# Remove NAs
text_in <- text_in[which(is.na(text_in)==FALSE)]
# For these procedures, object needs to be of class Corpus
text0 <- Corpus(VectorSource(text_in))
# Various text processing steps.
text <- TermDocumentMatrix(text0,
control =
list(removePunctuation = TRUE,
stopwords = TRUE,
tolower = TRUE,
stemming = FALSE,
removeNumbers = TRUE,
bounds = list(global = c(1, Inf))))
ft <- findFreqTerms(text, lowfreq = 4, highfreq = Inf)
ft_matrix <- as.matrix(text[ft,])
sorted_matrix <- data.frame(sort(apply(ft_matrix, 1, sum), decreasing = TRUE)) %>%
rownames_to_column()
sorted_matrix
sorted_matrix <- data.frame(sort(apply(ft_matrix, 1, sum), decreasing = TRUE)) %>%
rownames_to_column() %>%
rename("word" = "rowname",
"frequency" = "sort.apply.ft_matrix..1..sum...decreasing...TRUE.") %>%
filter(!(word %in% c("across", "using", "use", "pgdl", "present", "often", "however", "many",
"well", "usa", "two", "approach", "due", "-", "throughout", "large")))
webshot::install_phantomjs()
set.seed(1234)
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = plasma(50), backgroundColor = "black")
cloud
unique(sorted_matrix$word)
sorted_matrix <- data.frame(sort(apply(ft_matrix, 1, sum), decreasing = TRUE)) %>%
rownames_to_column() %>%
rename("word" = "rowname",
"frequency" = "sort.apply.ft_matrix..1..sum...decreasing...TRUE.") %>%
filter(!(word %in% c("across", "using", "use", "pgdl", "present", "often", "however", "many",
"well", "usa", "two", "approach", "due", "_", "throughout", "large")))
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = plasma(50), backgroundColor = "black")
cloud
sorted_matrix <- data.frame(sort(apply(ft_matrix, 1, sum), decreasing = TRUE)) %>%
rownames_to_column() %>%
rename("word" = "rowname",
"frequency" = "sort.apply.ft_matrix..1..sum...decreasing...TRUE.") %>%
filter(!(word %in% c("across", "using", "use", "pgdl", "present", "often", "however", "many",
"well", "usa", "two", "approach", "due", "_", "throughout", "large", "can")))
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = plasma(50), backgroundColor = "black")
cloud
sorted_matrix <- data.frame(sort(apply(ft_matrix, 1, sum), decreasing = TRUE)) %>%
rownames_to_column() %>%
rename("word" = "rowname",
"frequency" = "sort.apply.ft_matrix..1..sum...decreasing...TRUE.") %>%
filter(!(word %in% c("across", "using", "use", "pgdl", "present", "often", "however", "many",
"well", "usa", "two", "approach", "due", "_ ", "throughout", "large", "can")))
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = plasma(50), backgroundColor = "black")
View(sorted_matrix)
sorted_matrix <- data.frame(sort(apply(ft_matrix, 1, sum), decreasing = TRUE)) %>%
rownames_to_column() %>%
rename("word" = "rowname",
"frequency" = "sort.apply.ft_matrix..1..sum...decreasing...TRUE.") %>%
filter(!(word %in% c("across", "using", "use", "pgdl", "present", "often", "however", "many",
"well", "usa", "two", "approach", "due", "-", "throughout", "large", "can")))
View(sorted_matrix)
cloud <- wordcloud2(data = sorted_matrix[-36, ],
size = 1.6, color = plasma(50), backgroundColor = "black")
cloud
cloud <- wordcloud2(data = sorted_matrix[-36, ],
size = 1.6, color = plasma(50), backgroundColor = "white")
cloud
cloud <- wordcloud2(data = sorted_matrix[-36, ],
size = 1.6, color = plasma(40), backgroundColor = "white")
cloud
cloud <- wordcloud2(data = sorted_matrix[-36, ],
size = 1.6, color = plasma(30), backgroundColor = "white")
cloud
cloud <- wordcloud2(data = sorted_matrix[-36, ],
size = 1.6, color = plasma(37), backgroundColor = "white")
cloud
cloud <- wordcloud2(data = sorted_matrix[-36, ],
size = 1.6, color = plasma(34), backgroundColor = "white")
cloud
cloud
library(tidyverse)
library(tm)
library(wordcloud2)
library(viridis)
library(maps)
library(janitor)
library(htmlwidgets)
library(webshot)
set.seed(1234)
cloud <- wordcloud2(data = sorted_matrix[-36, ],
size = 1.6, color = plasma(34), backgroundColor = "white")
# Import each text file
whole_data <- read.csv(file = "../data/Virtual Summit_ Incorporating Open Science & Data Science Techniques in Limnology and Oceanography (Responses) - Form Responses 1.csv")
whole_data <- clean_names(whole_data)
data_science_abstracts <- whole_data %>%
filter(!(name %in% c("Corinna Gries", "Michael Meyer", "Eric Pedersen",
"Robert Ladwig", "Marcus Beck", "Clayton Williams",
"Mark Scheuerell", "Matthew R.V. Ross", "Jeff Hollister"))) %>%
select(name, talk_title, talk_abstract)
# First create text_in with only the abstracts
text_in <- data_science_abstracts$talk_abstract
# Remove NAs
text_in <- text_in[which(is.na(text_in)==FALSE)]
# For these procedures, object needs to be of class Corpus
text0 <- Corpus(VectorSource(text_in))
# Various text processing steps.
text <- TermDocumentMatrix(text0,
control =
list(removePunctuation = TRUE,
stopwords = TRUE,
tolower = TRUE,
stemming = FALSE,
removeNumbers = TRUE,
bounds = list(global = c(1, Inf))))
ft <- findFreqTerms(text, lowfreq = 4, highfreq = Inf)
ft_matrix <- as.matrix(text[ft,])
sorted_matrix <- data.frame(sort(apply(ft_matrix, 1, sum), decreasing = TRUE)) %>%
rownames_to_column() %>%
rename("word" = "rowname",
"frequency" = "sort.apply.ft_matrix..1..sum...decreasing...TRUE.") %>%
filter(!(word %in% c("across", "using", "use", "pgdl", "present", "often", "however", "many",
"well", "usa", "two", "approach", "due", "-", "throughout", "large", "can")))
set.seed(1234)
cloud <- wordcloud2(data = sorted_matrix[-36, ],
size = 1.6, color = plasma(34), backgroundColor = "white")
cloud
cloud <- wordcloud2(data = sorted_matrix[-36, ],
size = 1.6, color = plasma(37), backgroundColor = "white")
cloud
set.seed(1234)
cloud <- wordcloud2(data = sorted_matrix[-36, ],
size = 1.6, color = plasma(34), backgroundColor = "white")
cloud
cloud <- wordcloud2(data = sorted_matrix[-36, ],
size = 1.6, color = plasma(34), backgroundColor = "white")
cloud <- wordcloud2(data = sorted_matrix[-36, ],
size = 1.6, color = plasma(34), backgroundColor = "black")
cloud
open_science_abstracts <- whole_data %>%
filter(name %in% c("Corinna Gries", "Michael Meyer", "Eric Pedersen",
"Robert Ladwig", "Marcus Beck", "Clayton Williams",
"Mark Scheuerell", "Matthew R.V. Ross", "Jeff Hollister")) %>%
select(name, talk_title, talk_abstract)
# First create text_in with only the abstracts
text_in <- open_science_abstracts$talk_abstract
# Remove NAs
text_in <- text_in[which(is.na(text_in)==FALSE)]
# For these procedures, object needs to be of class Corpus
text0 <- Corpus(VectorSource(text_in))
# Various text processing steps.
text <- TermDocumentMatrix(text0,
control =
list(removePunctuation = TRUE,
stopwords = TRUE,
tolower = TRUE,
stemming = FALSE,
removeNumbers = TRUE,
bounds = list(global = c(1, Inf))))
ft <- findFreqTerms(text, lowfreq = 4, highfreq = Inf)
ft_matrix <- as.matrix(text[ft,])
sorted_matrix <- data.frame(sort(apply(ft_matrix, 1, sum), decreasing = TRUE)) %>%
rownames_to_column() %>%
rename("word" = "rowname",
"frequency" = "sort.apply.ft_matrix..1..sum...decreasing...TRUE.") %>%
filter(!(word %in% c("will", "using", "high", "may", "also", "often", "however", "many",
"well", "ler", "five")))
data_science_abstracts <- whole_data %>%
filter(!(name %in% c("Corinna Gries", "Michael Meyer", "Eric Pedersen",
"Robert Ladwig", "Marcus Beck", "Clayton Williams",
"Mark Scheuerell", "Matthew R.V. Ross", "Jeff Hollister"))) %>%
select(name, talk_title, talk_abstract)
# First create text_in with only the abstracts
text_in <- data_science_abstracts$talk_abstract
# Remove NAs
text_in <- text_in[which(is.na(text_in)==FALSE)]
# For these procedures, object needs to be of class Corpus
text0 <- Corpus(VectorSource(text_in))
# Various text processing steps.
text <- TermDocumentMatrix(text0,
control =
list(removePunctuation = TRUE,
stopwords = TRUE,
tolower = TRUE,
stemming = FALSE,
removeNumbers = TRUE,
bounds = list(global = c(1, Inf))))
ft <- findFreqTerms(text, lowfreq = 4, highfreq = Inf)
ft_matrix <- as.matrix(text[ft,])
sorted_matrix <- data.frame(sort(apply(ft_matrix, 1, sum), decreasing = TRUE)) %>%
rownames_to_column() %>%
rename("word" = "rowname",
"frequency" = "sort.apply.ft_matrix..1..sum...decreasing...TRUE.") %>%
filter(!(word %in% c("across", "using", "use", "pgdl", "present", "often", "however", "many",
"well", "usa", "two", "approach", "due", "-", "throughout", "large", "can")))
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = plasma(34), backgroundColor = "black")
cloud
cloud <- wordcloud2(data = sorted_matrix,
size = 1.6, color = plasma(34), backgroundColor = "white")
cloud
library(tidyverse)
library(tm)
library(wordcloud2)
library(viridis)
library(maps)
library(janitor)
library(htmlwidgets)
library(webshot)
cloud
sorted_matrix[-36, ]
cloud <- wordcloud2(data = sorted_matrix[-36, ],
size = 1.6, color = plasma(50), backgroundColor = "black")
cloud
set.seed(1234)
cloud <- wordcloud2(data = sorted_matrix[-36, ],
size = 1.6, color = plasma(50), backgroundColor = "white")
cloud
cloud <- wordcloud2(data = sorted_matrix[-36, ],
size = 1.6, color = plasma(50), backgroundColor = "black")
cloud
rm(list = ls())
library(tidyverse)
library(OpenStreetMap)
library(ggpubr)
library(cowplot)
library(ggrepel)
library(viridis)
metadata <- read.csv(file = "../cleaned_data/metadata.csv",
stringsAsFactors = FALSE)
setwd("C:/Users/michael.f.meyer/Dropbox/Baikal_sewage/R_scripts_numbered")
metadata <- read.csv(file = "../cleaned_data/metadata.csv",
stringsAsFactors = FALSE)
distance <- read.csv(file = "../cleaned_data/distance_weighted_population_metrics.csv",
header = TRUE, stringsAsFactors = FALSE)
sample_points <- full_join(x = metadata,
y = distance,
by = c("site"))
# Make the locs Mercator
sample_points_merc <- projectMercator(lat = sample_points$lat,
long = sample_points$long) %>%
as.data.frame() %>%
bind_cols(., sample_points)
# Get a basemap
# Options: https://www.r-bloggers.com/the-openstreetmap-package-opens-up/
base_map <- openmap(upperLeft = c(55.915113, 102.2324553),
lowerRight = c(51.1800703, 110.8),
type = "stamen-toner") %>%
openproj()
# Get a zoomed in map
base_map_zoom <- openmap(upperLeft = c(52.15, 104.75),
lowerRight = c(51.75, 105.55),
type = "bing", zoom = 11) %>%
openproj()
# Build the inset map with the basemap
inset_map <- autoplot(base_map) +
geom_point(data = sample_points_merc,
aes(x = long, y = lat,
fill = log10(distance_weighted_population)),
alpha = 1,  color = "grey70", size = 3,
shape = 21) +
scale_fill_viridis(option = "plasma") +
theme(axis.text.x = element_text(size = 10),
axis.text.y = element_text(size = 10),
plot.background = element_rect(fill = "snow1")) +
xlab("") +
ylab("") +
theme(legend.position = "none",
axis.title.x = element_blank(),
axis.title.y = element_blank())
# Build the inset map with the basemap
inset_map <- autoplot(base_map) +
# geom_point(data = sample_points_merc,
#            aes(x = long, y = lat,
#                fill = log10(distance_weighted_population)),
#            alpha = 1,  color = "grey70", size = 3,
#            shape = 21) +
# scale_fill_viridis(option = "plasma") +
theme(axis.text.x = element_text(size = 10),
axis.text.y = element_text(size = 10),
plot.background = element_rect(fill = "snow1")) +
xlab("") +
ylab("") +
theme(legend.position = "none",
axis.title.x = element_blank(),
axis.title.y = element_blank())
# Build a close up map with satellite imagery & zoomed in map
zoom_map <- autoplot(base_map_zoom) +
# geom_point(data = sample_points_merc,
#            aes(x = long, y = lat,
#                size = log10(distance_weighted_population),
#                fill = log10(distance_weighted_population)),
#            alpha = 0.8,  color = "grey70", shape = 21,
#            stroke = 2.5, size = 6, color = "blue") +
# scale_fill_viridis(option = "plasma", name = "log10(IDW Pop)") +
# scale_size_continuous(range = c(5, 20), guide = "none") +
xlab("Longitude") +
ylab("Latitude") +
annotate(geom = "text", label = "Bolshoe Goloustnoe",
x = 105.4, y = 52.06, color = "white", size = 10) +
annotate(geom = "text", label = "Bolshie Koty",
x = 105.075, y = 51.935, color = "white", size = 10) +
annotate(geom = "text", label = "Listvyanka",
x = 104.85, y = 51.9, color = "white", size = 10) +
theme(legend.key.height = unit(1, "in"),
legend.key.width = unit(0.65, "in"),
legend.text = element_text(size = 20),
legend.title = element_text(size = 24),
panel.background = element_blank(),
axis.title = element_text(size = 24),
axis.text = element_text(size = 20))
zoom_map
library(raster)
google_earth_outlines <- raster("../clean_disaggregated_data/Baikal_shapefile.kml")
library(sf)
google_earth_outlines <- sf::st_read(dsn = "../clean_disaggregated_data/Baikal_shapefile.kml")
sample_points <- full_join(x = metadata,
y = distance,
by = c("site"))
loc_areas <- baikal_shapefile %>%
filter(!grepl("shoreline", Name))
google_earth_outlines <- sf::st_read(dsn = "../clean_disaggregated_data/Baikal_shapefile.kml") %>%
filter(!grepl("shoreline", Name))
sample_points <- full_join(x = metadata,
y = distance,
by = c("site"))
# Make the locs Mercator
sample_points_merc <- projectMercator(lat = sample_points$lat,
long = sample_points$long) %>%
as.data.frame() %>%
bind_cols(., sample_points)
# Get a basemap
# Options: https://www.r-bloggers.com/the-openstreetmap-package-opens-up/
base_map <- openmap(upperLeft = c(55.915113, 102.2324553),
lowerRight = c(51.1800703, 110.8),
type = "stamen-toner") %>%
openproj()
# Get a zoomed in map
base_map_zoom <- openmap(upperLeft = c(52.15, 104.75),
lowerRight = c(51.75, 105.55),
type = "bing", zoom = 11) %>%
openproj()
# Build the inset map with the basemap
inset_map <- autoplot(base_map) +
# geom_point(data = sample_points_merc,
#            aes(x = long, y = lat,
#                fill = log10(distance_weighted_population)),
#            alpha = 1,  color = "grey70", size = 3,
#            shape = 21) +
# scale_fill_viridis(option = "plasma") +
theme(axis.text.x = element_text(size = 10),
axis.text.y = element_text(size = 10),
plot.background = element_rect(fill = "snow1")) +
xlab("") +
ylab("") +
theme(legend.position = "none",
axis.title.x = element_blank(),
axis.title.y = element_blank())
# Build a close up map with satellite imagery & zoomed in map
zoom_map <- autoplot(base_map_zoom) +
# geom_point(data = sample_points_merc,
#            aes(x = long, y = lat,
#                size = log10(distance_weighted_population),
#                fill = log10(distance_weighted_population)),
#            alpha = 0.8,  color = "grey70", shape = 21,
#            stroke = 2.5, size = 6, color = "blue") +
# scale_fill_viridis(option = "plasma", name = "log10(IDW Pop)") +
# scale_size_continuous(range = c(5, 20), guide = "none") +
geom_sf(data = google_earth_outlines) +
xlab("Longitude") +
ylab("Latitude") +
annotate(geom = "text", label = "Bolshoe Goloustnoe",
x = 105.4, y = 52.06, color = "white", size = 10) +
annotate(geom = "text", label = "Bolshie Koty",
x = 105.075, y = 51.935, color = "white", size = 10) +
annotate(geom = "text", label = "Listvyanka",
x = 104.85, y = 51.9, color = "white", size = 10) +
theme(legend.key.height = unit(1, "in"),
legend.key.width = unit(0.65, "in"),
legend.text = element_text(size = 20),
legend.title = element_text(size = 24),
panel.background = element_blank(),
axis.title = element_text(size = 24),
axis.text = element_text(size = 20))
zoom_map
CRS(base_map_zoom)
